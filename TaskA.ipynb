{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMit - Emotions in Italian\n",
    "## Emotion and Target detection\n",
    "### Emanuele Muzio - 0766230\n",
    "Il presente notebook rappresenta un'illustrazione dello svolgimento dei due task del contest EMit (Emotions in Italian):\n",
    "- il primo task, o Task A, è mirato alla classificazione dei sentimenti espressi dai messaggi sui social media riguardanti i prodotti RAI\n",
    "- il secondo task, o Task B, è mirato alla classificazione del target del messaggio, se sul topic o sulla direzione\n",
    "Entrambi i task sono classificazione multiclasse e multilabel (nel Task A abbiamo 8 emozioni di base, più _Love_, nel Task B il target può essere uno dei due, entrambi o nessuno).\n",
    "\n",
    "Ai fini della valutazione dei due task, sono stati forniti dei dataset da utilizzare sia per l'addestramento che per i test, comprensivi di annotazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import copy, os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report as cr, f1_score as f1\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import pickle \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#Import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "\n",
    "# Gestione delle emoji\n",
    "import emot as emot_imp\n",
    "emot = emot_imp.core.emot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Emotion detection\n",
    "\n",
    "Per andare a ricercare la massima precisione (sia per quanto riguarda i dati che il modello), verranno effettuate diverse prove:\n",
    "- dati: verranno effettuati dei test usando sia dei dati preprocessati che i dati originali (dal momento che il blocco BERT-like del nostro modello trae informazioni anche da punteggiatura, stopwords ecc...)\n",
    "- modello: verranno testati diverse combinazioni di iperparametri usando un approccio grid-like per trovare il modello migliore\n",
    "\n",
    "Per il primo task, procediamo in due step, partendo dal preprocessing del testo (rimozione stopwords, hashtag, menzioni, keyword RT, collegamenti ipertestuali) per poi andare alla classificazione.\n",
    "\n",
    "Per la tokenizzazione del testo è stato scelto un modello multilingua (dal momento che i messaggi riguardano un'emittente italiana) case-sensitive. \n",
    "\n",
    "Il supporto alle emoji/emoticons è stato aggiunto rilevando quelle presenti nel testo e facendo un resize del modello per poterle gestire.\n",
    "\n",
    "Il modello BERT-like da HuggingFace utilizzato è il seguente: _bert-base-multilingual-cased_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"release\\emit_2023-v1\\emit_train_A.csv\")\n",
    "text_prep = data[\"text\"]\n",
    "text = data[\"text\"]\n",
    "emotions = data.drop([\"id\",\"text\"], axis=1)\n",
    "emotions_prep = data.drop([\"id\",\"text\"], axis=1)\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "nltk.download('stopwords')\n",
    "stopwords_it = stopwords.words('italian')\n",
    "X_keywords = ['RT', 'FAV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che raccoglie i principali 4 controlli che vengono effettuati sul testo, ovvero: \n",
    "# - presenza di menzioni ad altri utenti\n",
    "# - presenza di collegamenti esterni\n",
    "# - presenza di keyword relative a X (RT, FAV, quest'ultima non presente nei nostri dati)\n",
    "# - presenza di stop-words in lingua italiana dalla lista fornita dal NaturalLanguageToolKit\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        if t.startswith('@') and len(t) > 1 or t.startswith('http') or t in X_keywords or t.lower() in stopwords_it:\n",
    "            continue\n",
    "        else:\n",
    "            new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def getHashtags(text):\n",
    "    hashtags = []\n",
    "    for t in text.split(\" \"):\n",
    "        if t.startswith('#') and len(t) > 1:\n",
    "            hashtags.append(t)\n",
    "        else:\n",
    "            continue\n",
    "    return hashtags\n",
    "\n",
    "def removeHashTags(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        if t.startswith('#') and len(t) > 1:\n",
    "            continue\n",
    "        else:\n",
    "            new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A: Preprocessing\n",
    "Al fine di valutare soltanto le parti più importanti dei messaggi, con un contributo semantico più corposo, sono state prese diverse decisioni:\n",
    "- Eliminazione delle menzioni degli utenti (nomi utenti già oscurati nel dataset utilizzato)\n",
    "- Eliminazione delle stopword da NLTK\n",
    "- Eliminazione delle keyword legate a X (RT per i retweet e FAV per i messaggi preferiti)\n",
    "- Eliminazione link esterni\n",
    "- Eliminazione hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo innanzitutto l'integrità dei dati di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è necessario fare imputazione in quanto non ci sono dati mancanti all'interno del dataset di addestramento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo anche velocemente quali sono le emozioni maggiormente espresse nei messaggi.\n",
    "\n",
    "Possiamo vedere come i messaggi esprimano emozioni variegate (con un picco nei messaggi di fiducia/incoraggiamento e un minimo nei messaggi che esprimono timore o paura, fatto comprensibile dal momento che la maggior parte dei commenti riguarda trasmissioni in onda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(emotions.columns, [emotions[column].sum() for column in emotions.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo adesso procedere al preprocessing del testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prep = text_prep.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo questo primo passo, è sorto un dubbio riguardante l'utilità degli hashtag e la conseguente decisione sul mantenerli o meno. \n",
    "La scelta finale è stata quella di rimuoverli, dal momento che gli hashtag più diffusi almeno in questa prima fase non aggiungono molto valore al testo essendo relativi al topic (generalmente il nome del programma televisivo interessato).\n",
    "\n",
    "Potrebbe essere interessante mantenere queste informazioni per fare uno studio di sentiment analysis differenziata per singolo programma televisivo, tuttavia non è il focus principale del progetto.\n",
    "\n",
    "Sono stati rilevati in totale 1126 hashtag unici su 5990 totali (in riferimento ai dati di addestramento), con una distribuzione sbilanciata fortemente verso i 20-30 circa più usati, che sono risultati essere hashtag relativi appunto al nome della trasmissione televisiva oggetto del testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_list = list(map(getHashtags, text_prep))\n",
    "hashtags = []\n",
    "\n",
    "for h in hashtag_list:\n",
    "    hashtags.extend(h)\n",
    "\n",
    "hashtags = list(sorted(hashtags))\n",
    "unique_hashtags = list(set(hashtags))\n",
    "hasht_count = [hashtags.count(h) for h in unique_hashtags]\n",
    "\n",
    "sorted_h = [x for _, x in sorted(zip(hasht_count, unique_hashtags), reverse=True)]\n",
    "sorted_h_c = list(sorted(hasht_count,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(sorted_h[:25], sorted_h_c[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prep = text_prep.apply(removeHashTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alcuni messaggi sono composti soltanto da menzioni \n",
    "o semplici hashtag, per cui facciamo una veloce pulizia prima di procedere \n",
    "(al contrario, alcuni messaggi non verrebbero processati dal tokenizer, causando degli errori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_prep)):\n",
    "    if(len(text_prep[i]) == 0):\n",
    "        text_prep.drop(i, axis=0, inplace=True)\n",
    "        emotions_prep.drop(i, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di procedere alla classificazione vera e propria, dobbiamo adattare il tokenizer alla presenza delle emoji nel testo, elemento importante per l'interpretazione dei messaggi.\n",
    "\n",
    "Facciamo quindi una ricerca di emoji ed emoticons presenti e aggiungiamole al tokenizer tramite la funzione add_tokens(), per poi fare un resize del modello e completare questo step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_emoji = emot.bulk_emoji(text_prep)\n",
    "\n",
    "unique_emoji = []\n",
    "\n",
    "for i in range(len(bulk_emoji)):\n",
    "    res = bulk_emoji[i]\n",
    "    if res['flag']:\n",
    "        unique_emoji.extend(res['value'])\n",
    "\n",
    "unique_emoji = list(set(unique_emoji))\n",
    "\n",
    "emoji_to_add = set(unique_emoji) - set(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_emoticons = emot.bulk_emoticons(text_prep)\n",
    "\n",
    "unique_emoticons = []\n",
    "\n",
    "for i in range(len(bulk_emoticons)):\n",
    "    res = bulk_emoticons[i]\n",
    "    if res['flag']:\n",
    "        unique_emoticons.extend(res['value'])\n",
    "\n",
    "unique_emoticons = list(set(unique_emoticons))\n",
    "\n",
    "emoticons_to_add = set(unique_emoticons) - set(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = []\n",
    "new_tokens.extend(emoji_to_add)\n",
    "new_tokens.extend(emoticons_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Adding: {len(new_tokens)} emoji/emoticons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo adesso di stabilire brevemente una lunghezza massima in parole dei messaggi.\n",
    "\n",
    "Possiamo vedere come la stragrande maggioranza dei messaggi abbia una lunghezza inferiore a 25-30 parole, per cui useremo 30 come tetto massimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(t.split(' ')) for t in text_prep])\n",
    "MAX_LEN = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come appare il testo dei messaggi dopo questa operazione di pulizia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[5], '\\n',text_prep[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Classificazione\n",
    "\n",
    "Arrivati a questo punto, dobbiamo per prima cosa addestrare il nostro classificatore per il task che dovrà svolgere.\n",
    "\n",
    "La struttura adottata sarà composta da un BTE (Bidirectional Transformer Encoder) per l'encoding degli embeddings generati dal tokenizer.\n",
    "A questa base aggiungiamo un layer dense e infine una sigmoide che ci permette di fare la classificazione multi-label richiesta.\n",
    "\n",
    "Procediamo a passare tutti i dati etichettati al nostro classificatore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    device = (\"cuda\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Dataset(Dataset):\n",
    "    def __init__(self, inputs, labels, tokenizer, MAX_LEN, transform=None):\n",
    "        self.transform = transform\n",
    "        self.inputs = inputs\n",
    "        self.labels = [torch.tensor(l) for l in labels]           \n",
    "        self.tokenizer = tokenizer\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = tokenizer(self.inputs.iloc[idx], add_special_tokens=True,\n",
    "                            return_tensors='pt', padding='max_length',\n",
    "                            max_length = self.MAX_LEN, truncation=True) \n",
    "        labels = self.labels[idx]\n",
    "        return {\n",
    "            'ids': inputs['input_ids'],\n",
    "            'mask': inputs['attention_mask'],\n",
    "            'token_type_ids': inputs['token_type_ids'],\n",
    "            'labels': labels\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTEClassifier(nn.Module):\n",
    "    def __init__(self, dropout, num_classes, bte):\n",
    "        super(BTEClassifier, self).__init__()\n",
    "        self.bte = bte # Blocco BTE - Bidirectional Transformer Encoder\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout), # Layer di dropout,\n",
    "            nn.Linear(768, num_classes), # Layer dense su cui fare fine tuning\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output = self.bte(ids, attention_mask = mask, token_type_ids = token_type_ids).last_hidden_state\n",
    "        output = output[:,0,:]\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss, accuracy, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    epoch_acc = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for d in tqdm(dataloader):\n",
    "        (ids, mask, token_type_ids, labels_) = d.values()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = ids.squeeze(1).to(device)\n",
    "        input_mask = mask.squeeze(1).to(device)\n",
    "        input_token_type_ids = token_type_ids.squeeze(1).to(device)\n",
    "        labels_ = labels_.squeeze(1).to(device).float()\n",
    "\n",
    "        output = model(input_ids, input_mask, input_token_type_ids)\n",
    "\n",
    "        batch_loss = loss(output, labels_)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_acc += accuracy(output, labels_).item()\n",
    "        \n",
    "        input_ids = input_ids.detach().cpu()\n",
    "        input_mask = input_mask.detach().cpu()\n",
    "        input_token_type_ids = input_token_type_ids.detach().cpu()\n",
    "        labels_ = labels_.detach().cpu()\n",
    "        \n",
    "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dataloader, loss, accuracy, device, best_acc, best_weights):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_acc = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(dataloader):\n",
    "            (ids, mask, token_type_ids, labels_) = d.values()\n",
    "\n",
    "            input_ids = ids.squeeze(1).to(device)\n",
    "            input_mask = mask.squeeze(1).to(device)\n",
    "            input_token_type_ids = token_type_ids.squeeze(1).to(device)\n",
    "            labels_ = labels_.squeeze(1).to(device).float()\n",
    "\n",
    "            output = model(input_ids, input_mask, input_token_type_ids)\n",
    "            \n",
    "            batch_loss = loss(output, labels_)\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            epoch_acc += accuracy(output, labels_).item()\n",
    "            \n",
    "            input_ids = input_ids.detach().cpu()\n",
    "            input_mask = input_mask.detach().cpu()\n",
    "            input_token_type_ids = input_token_type_ids.detach().cpu()\n",
    "            labels_ = labels_.detach().cpu()\n",
    "\n",
    "        acc = float(epoch_acc/len(dataloader))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader), best_acc, best_weights, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, epochs, optimizer, device, train_data, val_data,\n",
    "               batch_size, accuracy, loss, early_stopper):\n",
    "\n",
    "  train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "  val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "  # liste dei valori di loss e accuracy epoca per epoca per il plot\n",
    "  train_loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "  best_acc = - np.inf\n",
    "  best_weights = None\n",
    "\n",
    "  # Ciclo di addestramento \n",
    "  for epoch in tqdm(range(1, epochs+1)):\n",
    "    epoch_train_loss, epoch_train_acc, model = train(model, train_dataloader, loss, accuracy, optimizer, device)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    train_acc.append(epoch_train_acc)\n",
    "    \n",
    "    epoch_val_loss, epoch_val_acc, best_acc, best_weights, model = val(model, val_dataloader, loss, accuracy, device, best_acc, best_weights)\n",
    "    val_loss.append(epoch_val_loss)\n",
    "    val_acc.append(epoch_val_acc)\n",
    "\n",
    "    if early_stopper.early_stop(epoch_val_loss):             \n",
    "      break\n",
    "\n",
    "    print(f\"\\nTrain loss: {epoch_train_loss:6.4f} Val loss: {epoch_val_loss:6.4f}\")\n",
    "    print(f\"Train accuracy: {(epoch_train_acc):6.4f} Val accuracy: {(epoch_val_acc):6.4f}\")\n",
    "\n",
    "  return train_loss, val_loss, train_acc, val_acc, best_acc, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset):\n",
    "    dataloader = DataLoader(dataset)\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(dataloader):\n",
    "            (ids, mask, token_type_ids, labels_) = d.values()\n",
    "\n",
    "            input_ids = ids.squeeze(1).to(device)\n",
    "            input_mask = mask.squeeze(1).to(device)\n",
    "            input_token_type_ids = token_type_ids.squeeze(1).to(device)\n",
    "            labels_ = labels_.squeeze(1).to(device).float()\n",
    "\n",
    "            output = model(input_ids, input_mask, input_token_type_ids)\n",
    "\n",
    "            output = output.squeeze(0).detach().cpu().tolist()\n",
    "            pred = [1 if o > .5 else 0 for o in output]\n",
    "            input_ids= input_ids.detach().cpu()\n",
    "            input_mask = input_mask.detach().cpu()\n",
    "            input_token_type_ids = input_token_type_ids.detach().cpu()\n",
    "            labels_ = labels_.detach().cpu()\n",
    "            predictions.append(pred)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'dropout' : [0.1, 0.2, 0.3, 0.4],\n",
    "    'batch_size' : [4, 8, 16, 32],\n",
    "    'epochs' : [5, 10, 20],\n",
    "    'lr' : [1e-06, 1e-05, 1e-04, 1e-03],\n",
    "    'max_len' : MAX_LEN,\n",
    "    'num_classes' : 10,\n",
    "}\n",
    "\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(text, emotions.to_numpy(), test_size=0.3)\n",
    "train_dataset = _Dataset(X_train, Y_train, tokenizer, hyperparameters['max_len'])\n",
    "val_dataset = _Dataset(X_val, Y_val, tokenizer, hyperparameters['max_len'])\n",
    "\n",
    "X_train_prep, X_val_prep, Y_train_prep, Y_val_prep = train_test_split(text_prep, emotions_prep.to_numpy(), test_size=0.3)\n",
    "train_dataset_prep = _Dataset(X_train_prep, Y_train_prep, tokenizer, hyperparameters['max_len'])\n",
    "val_dataset_prep = _Dataset(X_val_prep, Y_val_prep, tokenizer, hyperparameters['max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = []\n",
    "runs = []\n",
    "n_runs = 5\n",
    "run = None\n",
    "i = 0\n",
    "\n",
    "if not os.path.exists('hist.pkl'):\n",
    "    while i < n_runs:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        accuracy = MultilabelAccuracy(num_labels=10).to(device)\n",
    "\n",
    "        dropout = rand.choice(hyperparameters['dropout'])\n",
    "        lr = rand.choice(hyperparameters['lr'])\n",
    "        epochs = rand.choice(hyperparameters['epochs'])\n",
    "        batch_size = rand.choice(hyperparameters['batch_size'])\n",
    "        run = [dropout, lr, epochs, batch_size]\n",
    "\n",
    "        if run in runs:\n",
    "            continue\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "        runs.append(run)\n",
    "        \n",
    "        early_stopper = EarlyStopper(patience=1, min_delta=0.008)\n",
    "        classifier = BTEClassifier(dropout, hyperparameters['num_classes'], model).to(device)\n",
    "        optimizer = Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "        train_loss, val_loss, train_acc, val_acc, best_acc, best_weights = evaluate(\n",
    "            classifier, \n",
    "            epochs, \n",
    "            optimizer, \n",
    "            device, \n",
    "            train_dataset, \n",
    "            val_dataset,\n",
    "            batch_size, \n",
    "            accuracy, \n",
    "            loss,\n",
    "            early_stopper\n",
    "        )\n",
    "\n",
    "        classifier = classifier.cpu()\n",
    "        accuracy = accuracy.cpu()\n",
    "        \n",
    "        hist.append(\n",
    "            {\n",
    "                \"epochs\" : epochs,\n",
    "                \"dropout\" : dropout,\n",
    "                \"lr\" : lr,\n",
    "                \"batch_size\" : batch_size,\n",
    "                \"train_loss\" : train_loss,\n",
    "                \"val_loss\" : val_loss,\n",
    "                \"train_acc\" : train_acc,\n",
    "                \"val_acc\" : val_acc,\n",
    "                \"best_acc\" : best_acc,\n",
    "                \"weights\" : best_weights\n",
    "            }\n",
    "        )\n",
    "    with open('hist.pkl', 'wb') as handle:\n",
    "        save = {\n",
    "            \"hist\" : hist,\n",
    "            \"runs\" : runs\n",
    "        }\n",
    "        pickle.dump(save, handle)\n",
    "else:\n",
    "    f = open(\"hist.pkl\",'rb')\n",
    "    save = pickle.load(f)\n",
    "    hist = save['hist']\n",
    "    runs = save['runs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots( nrows=2, ncols=3, figsize=(10, 10))\n",
    "n_epochs = list(range(0, 22, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i][j].set_title(f\"Lr:{lr}, epochs:{hist[i + j]['epochs']}, \\ndropout:{hist[i + j]['dropout']}, batch:{hist[i + j]['batch_size']}\")\n",
    "        ax[i][j].plot(hist[i + j]['train_loss'], label='training loss')\n",
    "        ax[i][j].plot(hist[i + j]['val_loss'], label='val loss')\n",
    "        ax[i][j].legend(loc='lower right')\n",
    "        ax[i][j].set_xticks(n_epochs)\n",
    "\n",
    "i = i - 1\n",
    "j = j + 1\n",
    "ax[i][j].set_title(f\"Lr:{lr}, epochs:{hist[i + j]['epochs']}, \\ndropout:{hist[i + j]['dropout']}, batch:{hist[i + j]['batch_size']}\")\n",
    "ax[i][j].plot(hist[i + j]['train_loss'], label='training loss')\n",
    "ax[i][j].plot(hist[i + j]['val_loss'], label='val loss')\n",
    "ax[i][j].legend(loc='lower right')\n",
    "ax[i][j].set_xticks(n_epochs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('train_A.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_hist = []\n",
    "prep_runs = []\n",
    "run = None\n",
    "i = 0\n",
    "\n",
    "if not os.path.exists('prep_hist.pkl'):\n",
    "    while i < n_runs:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        accuracy = MultilabelAccuracy(num_labels=10).to(device)\n",
    "        \n",
    "        dropout = rand.choice(hyperparameters['dropout'])\n",
    "        lr = rand.choice(hyperparameters['lr'])\n",
    "        epochs = rand.choice(hyperparameters['epochs'])\n",
    "        batch_size = rand.choice(hyperparameters['batch_size'])\n",
    "\n",
    "        run = [dropout, lr, epochs, batch_size]\n",
    "\n",
    "        if run in prep_runs:\n",
    "            continue\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "        prep_runs.append(run)\n",
    "        \n",
    "        early_stopper = EarlyStopper(patience=1, min_delta=0.008)\n",
    "        classifier = BTEClassifier(dropout, hyperparameters['num_classes'], model).to(device)\n",
    "        optimizer = Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "        train_loss, val_loss, train_acc, val_acc, best_acc, best_weights = evaluate(\n",
    "            classifier, \n",
    "            epochs, \n",
    "            optimizer, \n",
    "            device, \n",
    "            train_dataset_prep, \n",
    "            val_dataset_prep,\n",
    "            batch_size, \n",
    "            accuracy, \n",
    "            loss,\n",
    "            early_stopper\n",
    "        )\n",
    "\n",
    "        classifier = classifier.cpu()\n",
    "        accuracy = accuracy.cpu()\n",
    "\n",
    "        prep_hist.append(\n",
    "            {\n",
    "                \"epochs\" : epochs,\n",
    "                \"dropout\" : dropout,\n",
    "                \"lr\" : lr,\n",
    "                \"batch_size\" : batch_size,\n",
    "                \"train_loss\" : train_loss,\n",
    "                \"val_loss\" : val_loss,\n",
    "                \"train_acc\" : train_acc,\n",
    "                \"val_acc\" : val_acc,\n",
    "                \"best_acc\" : best_acc,\n",
    "                \"weights\" : best_weights\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with open('prep_hist.pkl', 'wb') as handle:\n",
    "        prep_save = {\n",
    "            \"hist\" : prep_hist,\n",
    "            \"runs\" : runs\n",
    "        }\n",
    "        pickle.dump(prep_save, handle)\n",
    "else:\n",
    "    f = open(\"prep_hist.pkl\",'r')\n",
    "    prep_save = pickle.load(f)\n",
    "    prep_hist = prep_save['hist']\n",
    "    prep_runs = prep_save['runs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( nrows=2, ncols=3, figsize=(10, 10))\n",
    "n_epochs = list(range(0, 22, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i][j].set_title(f\"Lr:{lr}, epochs:{prep_hist[i + j]['epochs']}, \\ndropout:{prep_hist[i + j]['dropout']}, batch:{prep_hist[i + j]['batch_size']}\")\n",
    "        ax[i][j].plot(prep_hist[i + j]['train_loss'], label='training loss')\n",
    "        ax[i][j].plot(prep_hist[i + j]['val_loss'], label='val loss')\n",
    "        ax[i][j].legend(loc='lower right')\n",
    "        ax[i][j].set_xticks(n_epochs)\n",
    "i = i - 1\n",
    "j = j + 1\n",
    "ax[i][j].set_title(f\"Lr:{lr}, epochs:{prep_hist[i + j]['epochs']}, \\ndropout:{prep_hist[i + j]['dropout']}, batch:{prep_hist[i + j]['batch_size']}\")\n",
    "ax[i][j].plot(prep_hist[i + j]['train_loss'], label='training loss')\n",
    "ax[i][j].plot(prep_hist[i + j]['val_loss'], label='val loss')\n",
    "ax[i][j].legend(loc='lower right')\n",
    "ax[i][j].set_xticks(n_epochs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('train_prep_A.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"release\\emit_2023-test-labels\\emit_test.csv\")\n",
    "test_prep = test.copy()\n",
    "\n",
    "test_ood = pd.read_csv(\"release\\emit_2023-test-labels\\emit_test_ood.csv\")\n",
    "test_ood_prep = test_ood.copy()\n",
    "\n",
    "test.drop([\"Topic\", \"Direction\"], axis=1, inplace=True)\n",
    "test_ood.drop([\"Topic\", \"Direction\"], axis=1, inplace=True)\n",
    "\n",
    "test_prep.drop([\"Topic\", \"Direction\"], axis=1, inplace=True)\n",
    "test_ood_prep.drop([\"Topic\", \"Direction\"], axis=1, inplace=True)\n",
    "\n",
    "test_prep['text'] = test_prep['text'].apply(preprocess).apply(removeHashTags)\n",
    "test_ood_prep['text'] = test_ood_prep['text'].apply(preprocess).apply(removeHashTags)\n",
    "\n",
    "test_prep = test_prep.loc[test_prep['text'].str.len() > 0]\n",
    "test_ood_prep = test_ood_prep.loc[test_ood_prep['text'].str.len() > 0]\n",
    "\n",
    "test_prep_dataset = _Dataset(test_prep['text'], test_prep.drop(['id','text'], axis=1).to_numpy(), tokenizer, hyperparameters['max_len'])\n",
    "test_ood_prep_dataset = _Dataset(test_ood_prep['text'], test_ood_prep.drop(['id','text'], axis=1).to_numpy(), tokenizer, hyperparameters['max_len'])\n",
    "\n",
    "test_dataset = _Dataset(test['text'], test.drop(['id','text'], axis=1).to_numpy(), tokenizer, hyperparameters['max_len'])\n",
    "test_ood_dataset = _Dataset(test_ood['text'], test_ood.drop(['id','text'], axis=1).to_numpy(), tokenizer, hyperparameters['max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(device)\n",
    "classes = emotions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('heatmap_A.png'):\n",
    "    preds = []\n",
    "    preds_ood = []\n",
    "    for h in hist:\n",
    "        weights = h['weights']\n",
    "\n",
    "        classifier.load_state_dict(weights)\n",
    "\n",
    "        preds.append(predict(classifier, test_dataset))\n",
    "        preds_ood.append(predict(classifier, test_ood_dataset))\n",
    "\n",
    "    target = test[classes].to_numpy()\n",
    "    target_ood = test_ood[classes].to_numpy()\n",
    "\n",
    "    f1_scores = [f1(pred, target, average='weighted') for pred in preds]\n",
    "    f1_ood_scores = [f1(ood_pred, target_ood, average='weighted') for ood_pred in preds_ood]\n",
    "\n",
    "    best_index = f1_scores.index(max(f1_scores))\n",
    "    best_hyperp = hist[best_index]\n",
    "    best_index_ood = f1_ood_scores.index(max(f1_ood_scores))\n",
    "    best_ood_hyperp = hist[best_index_ood]\n",
    "\n",
    "    if not os.path.exists('best_weights_a.pt'):\n",
    "        torch.save(best_hyperp['weights'], 'best_weights_a.pt')\n",
    "        torch.save(best_ood_hyperp['weights'], 'best_weights_ood_a.pt')\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(10, 10))\n",
    "\n",
    "    ax[0].set_title('In domain')\n",
    "    ax[1].set_title('OOD')\n",
    "    report = cr(preds[best_index], target, target_names=classes, output_dict=True)\n",
    "    report_ood = cr(preds_ood[best_index], target, target_names=classes, output_dict=True)\n",
    "    sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True, ax=ax[0]).get_figure()\n",
    "    sns.heatmap(pd.DataFrame(report_ood).iloc[:-1, :].T, annot=True, ax=ax[1]).get_figure()\n",
    "    fig.savefig('heatmap_A.png')\n",
    "\n",
    "    recap = open(\"recap.txt\", \"w\")\n",
    "    txt = [\n",
    "        \"lr;epochs;batch_size;dropout;ood;f1-score\", \n",
    "        f\"{best_hyperp['lr']};{best_hyperp['epochs']};{best_hyperp['batch_size']};{best_hyperp['dropout']};False;{max(f1_scores)}\",\n",
    "        f\"{best_ood_hyperp['lr']};{best_ood_hyperp['epochs']};{best_ood_hyperp['batch_size']}; {best_ood_hyperp['dropout']};True;{max(f1_ood_scores)}\"\n",
    "    ]\n",
    "    recap.write(\"\\n\".join(txt))\n",
    "    recap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('heatmap_prep_A.png'):\n",
    "    preds_prep = []\n",
    "    preds_ood_prep = []\n",
    "    for h in prep_hist:\n",
    "        weights = h['weights']\n",
    "\n",
    "        classifier.load_state_dict(weights)\n",
    "\n",
    "        preds_prep.append(predict(classifier, test_prep_dataset))\n",
    "        preds_ood_prep.append(predict(classifier, test_ood_prep_dataset))\n",
    "\n",
    "    target_prep = test_prep[classes].to_numpy()\n",
    "    target_prep_ood = test_ood_prep[classes].to_numpy()\n",
    "\n",
    "    f1_prep_scores = [f1(pred_prep, target_prep, average='weighted') for pred_prep in preds_prep]\n",
    "    f1_prep_ood_scores = [f1(ood_prep_pred, target_prep_ood, average='weighted') for ood_prep_pred in preds_ood_prep]\n",
    "\n",
    "    best_prep_index = f1_prep_scores.index(max(f1_prep_scores))\n",
    "    best_prep_hyperp = prep_hist[best_prep_index]\n",
    "\n",
    "    best_prep_index_ood = f1_prep_ood_scores.index(max(f1_prep_ood_scores))\n",
    "    best_prep_ood_hyperp = prep_hist[best_prep_index_ood]\n",
    "\n",
    "    if not os.path.exists('best_weights_prep_a.pt'):\n",
    "        torch.save(best_prep_hyperp['weights'], 'best_weights_prep_a.pt')\n",
    "        torch.save(best_prep_ood_hyperp['weights'], 'best_weights_ood_prep_a.pt')\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(10, 10))\n",
    "\n",
    "    ax[0].set_title('In domain')\n",
    "    ax[1].set_title('OOD')\n",
    "    report_prep = cr(preds_prep[best_prep_index], target_prep, target_names=classes, output_dict=True)\n",
    "    report_ood_prep = cr(preds_ood_prep[best_prep_index], target_prep, target_names=classes, output_dict=True)\n",
    "    sns.heatmap(pd.DataFrame(report_prep).iloc[:-1, :].T, annot=True, ax=ax[0]).get_figure()\n",
    "    sns.heatmap(pd.DataFrame(report_ood_prep).iloc[:-1, :].T, annot=True, ax=ax[1]).get_figure()\n",
    "    fig.savefig('heatmap_prep_A.png')\n",
    "    \n",
    "    recap = open(\"recap_prep.txt\", \"w\")\n",
    "    txt = [\n",
    "        \"lr;epochs;batch_size;dropout;ood;f1-score\", \n",
    "        f\"{best_prep_hyperp['lr']};{best_prep_hyperp['epochs']};{best_prep_hyperp['batch_size']};{best_prep_hyperp['dropout']};False;{max(f1_prep_scores)}\",\n",
    "        f\"{best_prep_ood_hyperp['lr']};{best_prep_ood_hyperp['epochs']};{best_prep_ood_hyperp['batch_size']}; {best_prep_ood_hyperp['dropout']};True;{max(f1_prep_ood_scores)}\"\n",
    "    ]\n",
    "    recap.write(\"\\n\".join(txt))\n",
    "    recap.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
